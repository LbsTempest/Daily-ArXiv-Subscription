---
title: Latest Papers - September 09, 2025
labels: documentation
---
**Please check the [Github page](https://github.com/zezhishao/MTS_Daily_ArXiv) for a better reading experience and more papers.**

## Speech Synthesis
| **Title** | **Link** | **Date** | **Comment** |
| --- | --- | --- | --- |
| **[Cloning a Conversational Voice AI Agent from Call\,Recording Datasets for Telesales](http://arxiv.org/abs/2509.04871v1)** |  | 2025-09-05 | 10 pages, 4 figures |
| **[Say More with Less: Variable-Frame-Rate Speech Tokenization via Adaptive Clustering and Implicit Duration Coding](http://arxiv.org/abs/2509.04685v1)** |  | 2025-09-04 |  |
| **[DarkStream: real-time speech anonymization with low latency](http://arxiv.org/abs/2509.04667v1)** |  | 2025-09-04 | <details><summary>Accep...</summary><p>Accepted for presentation at ASRU 2025</p></details> |
| **[AUDETER: A Large-scale Dataset for Deepfake Audio Detection in Open Worlds](http://arxiv.org/abs/2509.04345v1)** |  | 2025-09-04 |  |
| **[Exposing Synthetic Speech: Model Attribution and Detection of AI-generated Speech via Audio Fingerprints](http://arxiv.org/abs/2411.14013v3)** |  | 2025-09-04 |  |
| **[Open-Source Full-Duplex Conversational Datasets for Natural and Interactive Speech Synthesis](http://arxiv.org/abs/2509.04093v1)** |  | 2025-09-04 |  |
| **[LibriQuote: A Speech Dataset of Fictional Character Utterances for Expressive Zero-Shot Speech Synthesis](http://arxiv.org/abs/2509.04072v1)** |  | 2025-09-04 |  |
| **[Multi-level SSL Feature Gating for Audio Deepfake Detection](http://arxiv.org/abs/2509.03409v1)** |  | 2025-09-03 | <details><summary>This ...</summary><p>This paper has been accepted by ACM MM 2025</p></details> |
| **[I2TTS: Image-indicated Immersive Text-to-speech Synthesis with Spatial Perception](http://arxiv.org/abs/2411.13314v4)** |  | 2025-09-03 | <details><summary>Accep...</summary><p>Accepted by APSIPA ASC2025</p></details> |
| **[FELLE: Autoregressive Speech Synthesis with Token-Wise Coarse-to-Fine Flow Matching](http://arxiv.org/abs/2502.11128v2)** |  | 2025-09-03 | <details><summary>Accep...</summary><p>Accepted by ACM Multimedia 2025</p></details> |
| **[MixedG2P-T5: G2P-free Speech Synthesis for Mixed-script texts using Speech Self-Supervised Learning and Language Model](http://arxiv.org/abs/2509.01391v1)** |  | 2025-09-01 | <details><summary>In Pr...</summary><p>In Proceedings of the 17th Asia Pacific Signal and Information
  Processing Association Annual Summit and Conference (APSIPA ASC 2025)</p></details> |
| **[An AI-Based Shopping Assistant System to Support the Visually Impaired](http://arxiv.org/abs/2509.01246v1)** |  | 2025-09-01 | <details><summary>7 pag...</summary><p>7 pages, Accepted for 2025 SICE-FES conference (IEEE)</p></details> |
| **[FreeTalk:A plug-and-play and black-box defense against speech synthesis attacks](http://arxiv.org/abs/2509.00561v1)** |  | 2025-08-30 | under review |
| **[Parallel GPT: Harmonizing the Independence and Interdependence of Acoustic and Semantic Information for Zero-Shot Text-to-Speech](http://arxiv.org/abs/2508.04141v2)** |  | 2025-08-28 | <details><summary>Submi...</summary><p>Submitted to IEEE/ACM Transactions on Audio, Speech, and Language
  Processing (TASLP)</p></details> |
| **[ChipChat: Low-Latency Cascaded Conversational Agent in MLX](http://arxiv.org/abs/2509.00078v1)** |  | 2025-08-26 | ASRU 2025 |

## TTS
| **Title** | **Link** | **Date** | **Comment** |
| --- | --- | --- | --- |
| **[Mitigating Hallucinations in LM-Based TTS Models via Distribution Alignment Using GFlowNets](http://arxiv.org/abs/2508.15442v3)** |  | 2025-09-05 | <details><summary>Accep...</summary><p>Accepted to EMNLP 2025 Main Conference (Oral)</p></details> |
| **[You Sound a Little Tense: L2 Tailored Clear TTS Using Durational Vowel Properties](http://arxiv.org/abs/2506.23367v2)** |  | 2025-09-03 | <details><summary>Accep...</summary><p>Accepted to ISCA Speech Synthesis Workshop, 2025, Project webpage
  here: https://rosielab.github.io/clear_speech/ Code here:
  https://github.com/chocobearz/Matcha-TTS-L2-clarity</p></details> |
| **[MoTAS: MoE-Guided Feature Selection from TTS-Augmented Speech for Enhanced Multimodal Alzheimer's Early Screening](http://arxiv.org/abs/2508.20513v1)** |  | 2025-08-28 |  |
| **[Your Reward Function for RL is Your Best PRM for Search: Unifying RL and Search-Based TTS](http://arxiv.org/abs/2508.14313v2)** |  | 2025-08-22 |  |
| **[VisualSpeech: Enhancing Prosody Modeling in TTS Using Video](http://arxiv.org/abs/2501.19258v2)** |  | 2025-08-16 |  |
| **[MoE-TTS: Enhancing Out-of-Domain Text Understanding for Description-based TTS via Mixture-of-Experts](http://arxiv.org/abs/2508.11326v1)** |  | 2025-08-15 |  |
| **[Fairness in Dysarthric Speech Synthesis: Understanding Intrinsic Bias in Dysarthric Speech Cloning using F5-TTS](http://arxiv.org/abs/2508.05102v3)** |  | 2025-08-15 | <details><summary>Accep...</summary><p>Accepted at Interspeech 2025</p></details> |
| **[Facilitating Personalized TTS for Dysarthric Speakers Using Knowledge Anchoring and Curriculum Learning](http://arxiv.org/abs/2508.10412v1)** |  | 2025-08-14 | Interspeech 2025 |
| **[Improved Dysarthric Speech to Text Conversion via TTS Personalization](http://arxiv.org/abs/2508.06391v1)** |  | 2025-08-08 |  |
| **[The State Of TTS: A Case Study with Human Fooling Rates](http://arxiv.org/abs/2508.04179v1)** |  | 2025-08-06 | <details><summary>Accep...</summary><p>Accepted at InterSpeech 2025</p></details> |
| **[Toward Low-Latency End-to-End Voice Agents for Telecommunications Using Streaming ASR, Quantized LLMs, and Real-Time TTS](http://arxiv.org/abs/2508.04721v1)** |  | 2025-08-05 |  |
| **[A2TTS: TTS for Low Resource Indian Languages](http://arxiv.org/abs/2507.15272v1)** |  | 2025-07-21 |  |
| **[Differentiable Reward Optimization for LLM based TTS system](http://arxiv.org/abs/2507.05911v1)** |  | 2025-07-08 |  |
| **[A Dataset for Automatic Assessment of TTS Quality in Spanish](http://arxiv.org/abs/2507.01805v1)** |  | 2025-07-02 | <details><summary>5 pag...</summary><p>5 pages, 2 figures. Accepted at Interspeech 2025</p></details> |
| **[Multi-interaction TTS toward professional recording reproduction](http://arxiv.org/abs/2507.00808v2)** |  | 2025-07-02 | <details><summary>7 pag...</summary><p>7 pages,6 figures, Accepted to Speech Synthesis Workshop 2025 (SSW13)</p></details> |

## Audio Caption
| **Title** | **Link** | **Date** | **Comment** |
| --- | --- | --- | --- |
| **[MQAD: A Large-Scale Question Answering Dataset for Training Music Large Language Models](http://arxiv.org/abs/2508.19514v1)** |  | 2025-08-27 |  |
| **[Soundscape Captioning using Sound Affective Quality Network and Large Language Model](http://arxiv.org/abs/2406.05914v3)** |  | 2025-08-25 | <details><summary>IEEE ...</summary><p>IEEE Transactions on Multimedia, Code:
  https://github.com/Yuanbo2020/SoundSCaper</p></details> |
| **[DIFFA: Large Language Diffusion Models Can Listen and Understand](http://arxiv.org/abs/2507.18452v2)** |  | 2025-08-21 |  |
| **[CLAIR-A: Leveraging Large Language Models to Judge Audio Captions](http://arxiv.org/abs/2409.12962v2)** |  | 2025-08-11 | <details><summary>Accep...</summary><p>Accepted to ASRU 2025; Code is publicly available at
  https://github.com/DavidMChan/clair-a</p></details> |
| **[Auditory Intelligence: Understanding the World Through Sound](http://arxiv.org/abs/2508.07829v1)** |  | 2025-08-11 | <details><summary>Posit...</summary><p>Position paper without experimental/quantitative validation. Not
  submitted to any journal/conference</p></details> |
| **[MiDashengLM: Efficient Audio Understanding with General Audio Captions](http://arxiv.org/abs/2508.03983v1)** |  | 2025-08-06 |  |
| **[From Contrast to Commonality: Audio Commonality Captioning for Enhanced Audio-Text Cross-modal Understanding in Multimodal LLMs](http://arxiv.org/abs/2508.01659v1)** |  | 2025-08-03 |  |
| **[CatchPhrase: EXPrompt-Guided Encoder Adaptation for Audio-to-Image Generation](http://arxiv.org/abs/2507.18750v1)** |  | 2025-07-24 |  |
| **[Multiple Choice Learning of Low Rank Adapters for Language Modeling](http://arxiv.org/abs/2507.10419v1)** |  | 2025-07-14 |  |
| **[video-SALMONN 2: Captioning-Enhanced Audio-Visual Large Language Models](http://arxiv.org/abs/2506.15220v2)** |  | 2025-07-10 |  |
| **[SonicMotion: Dynamic Spatial Audio Soundscapes with Latent Diffusion Models](http://arxiv.org/abs/2507.07318v1)** |  | 2025-07-09 |  |
| **[MusiScene: Leveraging MU-LLaMA for Scene Imagination and Enhanced Video Background Music Generation](http://arxiv.org/abs/2507.05894v1)** |  | 2025-07-08 |  |
| **[SonicVerse: Multi-Task Learning for Music Feature-Informed Captioning](http://arxiv.org/abs/2506.15154v1)** |  | 2025-06-18 | <details><summary>14 pa...</summary><p>14 pages, 2 figures, Accepted to AIMC 2025</p></details> |
| **[AC/DC: LLM-based Audio Comprehension via Dialogue Continuation](http://arxiv.org/abs/2506.10312v1)** |  | 2025-06-12 | <details><summary>Accep...</summary><p>Accepted to Interspeech 2025</p></details> |
| **[Enhancing Retrieval-Augmented Audio Captioning with Generation-Assisted Multimodal Querying and Progressive Learning](http://arxiv.org/abs/2410.10913v3)** |  | 2025-06-10 |  |

## Speech language model
| **Title** | **Link** | **Date** | **Comment** |
| --- | --- | --- | --- |
| **[Say More with Less: Variable-Frame-Rate Speech Tokenization via Adaptive Clustering and Implicit Duration Coding](http://arxiv.org/abs/2509.04685v1)** |  | 2025-09-04 |  |
| **[OSUM-EChat: Enhancing End-to-End Empathetic Spoken Chatbot via Understanding-Driven Spoken Dialogue](http://arxiv.org/abs/2508.09600v2)** |  | 2025-09-03 |  |
| **[Entropy-based Coarse and Compressed Semantic Speech Representation Learning](http://arxiv.org/abs/2509.00503v1)** |  | 2025-08-30 |  |
| **[CodecBench: A Comprehensive Benchmark for Acoustic and Semantic Evaluation](http://arxiv.org/abs/2508.20660v1)** |  | 2025-08-28 |  |
| **[FlowDubber: Movie Dubbing with LLM-based Semantic-aware Learning and Flow Matching based Voice Enhancing](http://arxiv.org/abs/2505.01263v2)** |  | 2025-08-25 |  |
| **[TaDiCodec: Text-aware Diffusion Speech Tokenizer for Speech Language Modeling](http://arxiv.org/abs/2508.16790v1)** |  | 2025-08-22 |  |
| **[LLaSO: A Foundational Framework for Reproducible Research in Large Language and Speech Model](http://arxiv.org/abs/2508.15418v1)** |  | 2025-08-21 |  |
| **[Benchmarking Prosody Encoding in Discrete Speech Tokens](http://arxiv.org/abs/2508.11224v1)** |  | 2025-08-15 | Accepted by ASRU2025 |
| **[DualSpeechLM: Towards Unified Speech Understanding and Generation via Dual Speech Token Modeling with Large Language Models](http://arxiv.org/abs/2508.08961v2)** |  | 2025-08-13 |  |
| **[Dual Information Speech Language Models for Emotional Conversations](http://arxiv.org/abs/2508.08095v1)** |  | 2025-08-11 | <details><summary>Prese...</summary><p>Presented at IEEE ICME 2025</p></details> |
| **[Think Before You Talk: Enhancing Meaningful Dialogue Generation in Full-Duplex Speech Language Models with Planning-Inspired Text Guidance](http://arxiv.org/abs/2508.07375v1)** |  | 2025-08-10 | Work in progress |
| **[Incorporating Contextual Paralinguistic Understanding in Large Speech-Language Models](http://arxiv.org/abs/2508.07273v1)** |  | 2025-08-10 | <details><summary>Accep...</summary><p>Accepted at (ASRU 2025) 2025 IEEE Automatic Speech Recognition and
  Understanding Workshop</p></details> |
| **[ProsodyLM: Uncovering the Emerging Prosody Processing Capabilities in Speech Language Models](http://arxiv.org/abs/2507.20091v2)** |  | 2025-08-07 |  |
| **[Recent Advances in Speech Language Models: A Survey](http://arxiv.org/abs/2410.03751v4)** |  | 2025-08-07 | <details><summary>The r...</summary><p>The reduced version of this paper has been accepted at ACL 2025</p></details> |
| **[What Makes a Good Speech Tokenizer for LLM-Centric Speech Generation? A Systematic Study](http://arxiv.org/abs/2506.12537v2)** |  | 2025-08-05 |  |
