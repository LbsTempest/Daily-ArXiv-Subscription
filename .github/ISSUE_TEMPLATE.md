---
title: Latest Papers - August 27, 2025
labels: documentation
---
**Please check the [Github page](https://github.com/zezhishao/MTS_Daily_ArXiv) for a better reading experience and more papers.**

## Speech Synthesis
| **Title** | **Link** | **Date** | **Comment** |
| --- | --- | --- | --- |
| **[Towards Controllable Speech Synthesis in the Era of Large Language Models: A Systematic Survey](http://arxiv.org/abs/2412.06602v3)** |  | 2025-08-25 | <details><summary>The f...</summary><p>The first comprehensive survey on controllable TTS. Accepted to the
  EMNLP 2025 main conference</p></details> |
| **[ClearMask: Noise-Free and Naturalness-Preserving Protection Against Voice Deepfake Attacks](http://arxiv.org/abs/2508.17660v1)** |  | 2025-08-25 | <details><summary>14 Pa...</summary><p>14 Pages, Accepted by AsiaCCS 2025</p></details> |
| **[Improving French Synthetic Speech Quality via SSML Prosody Control](http://arxiv.org/abs/2508.17494v1)** |  | 2025-08-24 | <details><summary>13 pa...</summary><p>13 pages, 9 figures, 6 tables. Accepted for presentation at ICNLSP
  2025 (Odense, Denmark). Code and demo:
  https://github.com/hi-paris/Prosody-Control-French-TTS. ACM Class: I.2.7;
  H.5.5</p></details> |
| **[Enhancing Code-switched Text-to-Speech Synthesis Capability in Large Language Models with only Monolingual Corpora](http://arxiv.org/abs/2409.10969v2)** |  | 2025-08-22 | Accepted to ASRU2025 |
| **[Long-Context Speech Synthesis with Context-Aware Memory](http://arxiv.org/abs/2508.14713v1)** |  | 2025-08-20 | <details><summary>Accep...</summary><p>Accepted by Interspeech25</p></details> |
| **[Improving Resource-Efficient Speech Enhancement via Neural Differentiable DSP Vocoder Refinement](http://arxiv.org/abs/2508.14709v1)** |  | 2025-08-20 | <details><summary>Accep...</summary><p>Accepted to the 2025 IEEE Automatic Speech Recognition and
  Understanding Workshop (ASRU)</p></details> |
| **[FMSD-TTS: Few-shot Multi-Speaker Multi-Dialect Text-to-Speech Synthesis for Ãœ-Tsang, Amdo and Kham Speech Dataset Generation](http://arxiv.org/abs/2505.14351v3)** |  | 2025-08-20 | 18 pages |
| **[Integrating Feedback Loss from Bi-modal Sarcasm Detector for Sarcastic Speech Synthesis](http://arxiv.org/abs/2508.13028v1)** |  | 2025-08-18 | <details><summary>Speec...</summary><p>Speech Synthesis Workshop 2025</p></details> |
| **[Real-Time Sign Language Gestures to Speech Transcription using Deep Learning](http://arxiv.org/abs/2508.12713v1)** |  | 2025-08-18 | <details><summary>Cours...</summary><p>Course related research project</p></details> |
| **[Fairness in Dysarthric Speech Synthesis: Understanding Intrinsic Bias in Dysarthric Speech Cloning using F5-TTS](http://arxiv.org/abs/2508.05102v3)** |  | 2025-08-15 | <details><summary>Accep...</summary><p>Accepted at Interspeech 2025</p></details> |
| **[Facilitating Personalized TTS for Dysarthric Speakers Using Knowledge Anchoring and Curriculum Learning](http://arxiv.org/abs/2508.10412v1)** |  | 2025-08-14 | Interspeech 2025 |
| **[Marco-Voice Technical Report](http://arxiv.org/abs/2508.02038v4)** |  | 2025-08-14 | <details><summary>Techn...</summary><p>Technical Report. Our code and dataset are publicly available at
  https://github.com/AIDC-AI/Marco-Voice and
  https://huggingface.co/datasets/AIDC-AI/CSEMOTIONS respectively</p></details> |
| **[Fake-Mamba: Real-Time Speech Deepfake Detection Using Bidirectional Mamba as Self-Attention's Alternative](http://arxiv.org/abs/2508.09294v1)** |  | 2025-08-12 | <details><summary>Accep...</summary><p>Accepted at IEEE ASRU 2025</p></details> |
| **[Maestro-EVC: Controllable Emotional Voice Conversion Guided by References and Explicit Prosody](http://arxiv.org/abs/2508.06890v1)** |  | 2025-08-09 | <details><summary>Accep...</summary><p>Accepted at ASRU 2025</p></details> |
| **[Text to Speech System for Meitei Mayek Script](http://arxiv.org/abs/2508.06870v1)** |  | 2025-08-09 |  |

## TTS
| **Title** | **Link** | **Date** | **Comment** |
| --- | --- | --- | --- |
| **[Mitigating Hallucinations in LM-Based TTS Models via Distribution Alignment Using GFlowNets](http://arxiv.org/abs/2508.15442v2)** |  | 2025-08-24 |  |
| **[Your Reward Function for RL is Your Best PRM for Search: Unifying RL and Search-Based TTS](http://arxiv.org/abs/2508.14313v2)** |  | 2025-08-22 |  |
| **[VisualSpeech: Enhancing Prosody Modeling in TTS Using Video](http://arxiv.org/abs/2501.19258v2)** |  | 2025-08-16 |  |
| **[MoE-TTS: Enhancing Out-of-Domain Text Understanding for Description-based TTS via Mixture-of-Experts](http://arxiv.org/abs/2508.11326v1)** |  | 2025-08-15 |  |
| **[Fairness in Dysarthric Speech Synthesis: Understanding Intrinsic Bias in Dysarthric Speech Cloning using F5-TTS](http://arxiv.org/abs/2508.05102v3)** |  | 2025-08-15 | <details><summary>Accep...</summary><p>Accepted at Interspeech 2025</p></details> |
| **[Facilitating Personalized TTS for Dysarthric Speakers Using Knowledge Anchoring and Curriculum Learning](http://arxiv.org/abs/2508.10412v1)** |  | 2025-08-14 | Interspeech 2025 |
| **[Improved Dysarthric Speech to Text Conversion via TTS Personalization](http://arxiv.org/abs/2508.06391v1)** |  | 2025-08-08 |  |
| **[The State Of TTS: A Case Study with Human Fooling Rates](http://arxiv.org/abs/2508.04179v1)** |  | 2025-08-06 | <details><summary>Accep...</summary><p>Accepted at InterSpeech 2025</p></details> |
| **[Toward Low-Latency End-to-End Voice Agents for Telecommunications Using Streaming ASR, Quantized LLMs, and Real-Time TTS](http://arxiv.org/abs/2508.04721v1)** |  | 2025-08-05 |  |
| **[A2TTS: TTS for Low Resource Indian Languages](http://arxiv.org/abs/2507.15272v1)** |  | 2025-07-21 |  |
| **[Differentiable Reward Optimization for LLM based TTS system](http://arxiv.org/abs/2507.05911v1)** |  | 2025-07-08 |  |
| **[A Dataset for Automatic Assessment of TTS Quality in Spanish](http://arxiv.org/abs/2507.01805v1)** |  | 2025-07-02 | <details><summary>5 pag...</summary><p>5 pages, 2 figures. Accepted at Interspeech 2025</p></details> |
| **[Multi-interaction TTS toward professional recording reproduction](http://arxiv.org/abs/2507.00808v2)** |  | 2025-07-02 | <details><summary>7 pag...</summary><p>7 pages,6 figures, Accepted to Speech Synthesis Workshop 2025 (SSW13)</p></details> |
| **[You Sound a Little Tense: L2 Tailored Clear TTS Using Durational Vowel Properties](http://arxiv.org/abs/2506.23367v1)** |  | 2025-06-29 | <details><summary>Accep...</summary><p>Accepted to ISCA Speech Synthesis Workshop, 2025</p></details> |
| **[An Exploration of ECAPA-TDNN and x-vector Speaker Representations in Zero-shot Multi-speaker TTS](http://arxiv.org/abs/2506.20190v1)** |  | 2025-06-25 | Accepted to TSD 2025 |

## Audio Caption
| **Title** | **Link** | **Date** | **Comment** |
| --- | --- | --- | --- |
| **[Soundscape Captioning using Sound Affective Quality Network and Large Language Model](http://arxiv.org/abs/2406.05914v3)** |  | 2025-08-25 | <details><summary>IEEE ...</summary><p>IEEE Transactions on Multimedia, Code:
  https://github.com/Yuanbo2020/SoundSCaper</p></details> |
| **[DIFFA: Large Language Diffusion Models Can Listen and Understand](http://arxiv.org/abs/2507.18452v2)** |  | 2025-08-21 |  |
| **[CLAIR-A: Leveraging Large Language Models to Judge Audio Captions](http://arxiv.org/abs/2409.12962v2)** |  | 2025-08-11 | <details><summary>Accep...</summary><p>Accepted to ASRU 2025; Code is publicly available at
  https://github.com/DavidMChan/clair-a</p></details> |
| **[Auditory Intelligence: Understanding the World Through Sound](http://arxiv.org/abs/2508.07829v1)** |  | 2025-08-11 | <details><summary>Posit...</summary><p>Position paper without experimental/quantitative validation. Not
  submitted to any journal/conference</p></details> |
| **[MiDashengLM: Efficient Audio Understanding with General Audio Captions](http://arxiv.org/abs/2508.03983v1)** |  | 2025-08-06 |  |
| **[From Contrast to Commonality: Audio Commonality Captioning for Enhanced Audio-Text Cross-modal Understanding in Multimodal LLMs](http://arxiv.org/abs/2508.01659v1)** |  | 2025-08-03 |  |
| **[CatchPhrase: EXPrompt-Guided Encoder Adaptation for Audio-to-Image Generation](http://arxiv.org/abs/2507.18750v1)** |  | 2025-07-24 |  |
| **[Multiple Choice Learning of Low Rank Adapters for Language Modeling](http://arxiv.org/abs/2507.10419v1)** |  | 2025-07-14 |  |
| **[video-SALMONN 2: Captioning-Enhanced Audio-Visual Large Language Models](http://arxiv.org/abs/2506.15220v2)** |  | 2025-07-10 |  |
| **[SonicMotion: Dynamic Spatial Audio Soundscapes with Latent Diffusion Models](http://arxiv.org/abs/2507.07318v1)** |  | 2025-07-09 |  |
| **[MusiScene: Leveraging MU-LLaMA for Scene Imagination and Enhanced Video Background Music Generation](http://arxiv.org/abs/2507.05894v1)** |  | 2025-07-08 |  |
| **[SonicVerse: Multi-Task Learning for Music Feature-Informed Captioning](http://arxiv.org/abs/2506.15154v1)** |  | 2025-06-18 | <details><summary>14 pa...</summary><p>14 pages, 2 figures, Accepted to AIMC 2025</p></details> |
| **[AC/DC: LLM-based Audio Comprehension via Dialogue Continuation](http://arxiv.org/abs/2506.10312v1)** |  | 2025-06-12 | <details><summary>Accep...</summary><p>Accepted to Interspeech 2025</p></details> |
| **[Enhancing Retrieval-Augmented Audio Captioning with Generation-Assisted Multimodal Querying and Progressive Learning](http://arxiv.org/abs/2410.10913v3)** |  | 2025-06-10 |  |
| **[CapSpeech: Enabling Downstream Applications in Style-Captioned Text-to-Speech](http://arxiv.org/abs/2506.02863v1)** |  | 2025-06-03 |  |

## Speech language model
| **Title** | **Link** | **Date** | **Comment** |
| --- | --- | --- | --- |
| **[FlowDubber: Movie Dubbing with LLM-based Semantic-aware Learning and Flow Matching based Voice Enhancing](http://arxiv.org/abs/2505.01263v2)** |  | 2025-08-25 |  |
| **[TaDiCodec: Text-aware Diffusion Speech Tokenizer for Speech Language Modeling](http://arxiv.org/abs/2508.16790v1)** |  | 2025-08-22 |  |
| **[LLaSO: A Foundational Framework for Reproducible Research in Large Language and Speech Model](http://arxiv.org/abs/2508.15418v1)** |  | 2025-08-21 |  |
| **[Benchmarking Prosody Encoding in Discrete Speech Tokens](http://arxiv.org/abs/2508.11224v1)** |  | 2025-08-15 | Accepted by ASRU2025 |
| **[OSUM-EChat: Enhancing End-to-End Empathetic Spoken Chatbot via Understanding-Driven Spoken Dialogue](http://arxiv.org/abs/2508.09600v1)** |  | 2025-08-13 |  |
| **[DualSpeechLM: Towards Unified Speech Understanding and Generation via Dual Speech Token Modeling with Large Language Models](http://arxiv.org/abs/2508.08961v2)** |  | 2025-08-13 |  |
| **[Dual Information Speech Language Models for Emotional Conversations](http://arxiv.org/abs/2508.08095v1)** |  | 2025-08-11 | <details><summary>Prese...</summary><p>Presented at IEEE ICME 2025</p></details> |
| **[Think Before You Talk: Enhancing Meaningful Dialogue Generation in Full-Duplex Speech Language Models with Planning-Inspired Text Guidance](http://arxiv.org/abs/2508.07375v1)** |  | 2025-08-10 | Work in progress |
| **[Incorporating Contextual Paralinguistic Understanding in Large Speech-Language Models](http://arxiv.org/abs/2508.07273v1)** |  | 2025-08-10 | <details><summary>Accep...</summary><p>Accepted at (ASRU 2025) 2025 IEEE Automatic Speech Recognition and
  Understanding Workshop</p></details> |
| **[ProsodyLM: Uncovering the Emerging Prosody Processing Capabilities in Speech Language Models](http://arxiv.org/abs/2507.20091v2)** |  | 2025-08-07 |  |
| **[Recent Advances in Speech Language Models: A Survey](http://arxiv.org/abs/2410.03751v4)** |  | 2025-08-07 | <details><summary>The r...</summary><p>The reduced version of this paper has been accepted at ACL 2025</p></details> |
| **[What Makes a Good Speech Tokenizer for LLM-Centric Speech Generation? A Systematic Study](http://arxiv.org/abs/2506.12537v2)** |  | 2025-08-05 |  |
| **[Hearing More with Less: Multi-Modal Retrieval-and-Selection Augmented Conversational LLM-Based ASR](http://arxiv.org/abs/2508.01166v1)** |  | 2025-08-02 |  |
| **[Scaling Analysis of Interleaved Speech-Text Language Models](http://arxiv.org/abs/2504.02398v2)** |  | 2025-07-27 | <details><summary>Accep...</summary><p>Accepted at COLM 2025</p></details> |
| **[SALM-Duplex: Efficient and Direct Duplex Modeling for Speech-to-Speech Language Model](http://arxiv.org/abs/2505.15670v4)** |  | 2025-07-25 | <details><summary>Accep...</summary><p>Accepted to Interspeech 2025</p></details> |
