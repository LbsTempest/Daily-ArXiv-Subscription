---
title: Latest Papers - November 11, 2025
labels: documentation
---
**Please check the [Github page](https://github.com/LbsTempest/Daily-ArXiv-Subscription) for a better reading experience and more papers.**

## Speech Synthesis
| **Title** | **Link** | **Date** | **Comment** |
| --- | --- | --- | --- |
| **[Reconstructing Unseen Sentences from Speech-related Biosignals for Open-vocabulary Neural Communication](http://arxiv.org/abs/2510.27247v1)** |  | 2025-10-31 | <details><summary>Accep...</summary><p>Accepted for publication in IEEE Transactions on Neural Systems and
  Rehabilitation Engineering</p></details> |
| **[SoulX-Podcast: Towards Realistic Long-form Podcasts with Dialectal and Paralinguistic Diversity](http://arxiv.org/abs/2510.23541v2)** |  | 2025-10-28 |  |
| **[DrVoice: Parallel Speech-Text Voice Conversation Model via Dual-Resolution Speech Representations](http://arxiv.org/abs/2506.09349v3)** |  | 2025-10-28 | Work in progress |
| **[SFMS-ALR: Script-First Multilingual Speech Synthesis with Adaptive Locale Resolution](http://arxiv.org/abs/2510.25178v1)** |  | 2025-10-27 | <details><summary>10 pa...</summary><p>10 pages, 2 figures, 1 table. Demonstration prototype available at
  https://sfml-tts-proxy-253495793487.us-central1.run.app</p></details> |
| **[UltraVoice: Scaling Fine-Grained Style-Controlled Speech Conversations for Spoken Dialogue Models](http://arxiv.org/abs/2510.22588v1)** |  | 2025-10-26 | 23 pages, 4 figures |
| **[Efficient Speech Language Modeling via Energy Distance in Continuous Latent Space](http://arxiv.org/abs/2505.13181v2)** |  | 2025-10-24 | <details><summary>NeurI...</summary><p>NeurIPS 2025; Demos and code are available at
  https://github.com/ictnlp/SLED-TTS</p></details> |
| **[Continuous-Token Diffusion for Speaker-Referenced TTS in Multimodal LLMs](http://arxiv.org/abs/2510.12995v2)** |  | 2025-10-23 |  |
| **[Shallow Flow Matching for Coarse-to-Fine Text-to-Speech Synthesis](http://arxiv.org/abs/2505.12226v2)** |  | 2025-10-23 | <details><summary>Accep...</summary><p>Accepted by NeurIPS 2025</p></details> |
| **[Vox-Evaluator: Enhancing Stability and Fidelity for Zero-shot TTS with A Multi-Level Evaluator](http://arxiv.org/abs/2510.20210v1)** |  | 2025-10-23 | 10 pages, 5 figures |
| **[U-Codec: Ultra Low Frame-rate Neural Speech Codec for Fast High-fidelity Speech Generation](http://arxiv.org/abs/2510.16718v1)** |  | 2025-10-19 |  |
| **[DiEmo-TTS: Disentangled Emotion Representations via Self-Supervised Distillation for Cross-Speaker Emotion Transfer in Text-to-Speech](http://arxiv.org/abs/2505.19687v2)** |  | 2025-10-17 | <details><summary>Proce...</summary><p>Proceedings of Interspeech 2025</p></details> |
| **[RLAIF-SPA: Optimizing LLM-based Emotional Speech Synthesis via RLAIF](http://arxiv.org/abs/2510.14628v1)** |  | 2025-10-16 |  |
| **[Closing the Gap Between Text and Speech Understanding in LLMs](http://arxiv.org/abs/2510.13632v1)** |  | 2025-10-15 |  |
| **[ParsVoice: A Large-Scale Multi-Speaker Persian Speech Corpus for Text-to-Speech Synthesis](http://arxiv.org/abs/2510.10774v2)** |  | 2025-10-14 |  |
| **[BridgeCode: A Dual Speech Representation Paradigm for Autoregressive Zero-Shot Text-to-Speech Synthesis](http://arxiv.org/abs/2510.11646v1)** |  | 2025-10-13 |  |

## TTS
| **Title** | **Link** | **Date** | **Comment** |
| --- | --- | --- | --- |
| **[SP-MCQA: Evaluating Intelligibility of TTS Beyond the Word Level](http://arxiv.org/abs/2510.26190v1)** |  | 2025-10-30 |  |
| **[Continuous-Token Diffusion for Speaker-Referenced TTS in Multimodal LLMs](http://arxiv.org/abs/2510.12995v2)** |  | 2025-10-23 |  |
| **[Vox-Evaluator: Enhancing Stability and Fidelity for Zero-shot TTS with A Multi-Level Evaluator](http://arxiv.org/abs/2510.20210v1)** |  | 2025-10-23 | 10 pages, 5 figures |
| **[HaTT: Hadamard avoiding TT recompression](http://arxiv.org/abs/2410.04385v2)** |  | 2025-10-19 | <details><summary>31 pa...</summary><p>31 pages, 13 figures, 3 tables</p></details> |
| **[Mismatch Aware Guidance for Robust Emotion Control in Auto-Regressive TTS Models](http://arxiv.org/abs/2510.13293v1)** |  | 2025-10-15 | <details><summary>Submi...</summary><p>Submitted to ICASSP 2026</p></details> |
| **[Perturbation Self-Supervised Representations for Cross-Lingual Emotion TTS: Stage-Wise Modeling of Emotion and Speaker](http://arxiv.org/abs/2510.11124v1)** |  | 2025-10-13 | <details><summary>Submi...</summary><p>Submitted to Expert Systems with Applications,11 pages</p></details> |
| **[EMORL-TTS: Reinforcement Learning for Fine-Grained Emotion Control in LLM-based TTS](http://arxiv.org/abs/2510.05758v1)** |  | 2025-10-07 | <details><summary>Under...</summary><p>Under review for ICASSP 2026</p></details> |
| **[Speak, Edit, Repeat: High-Fidelity Voice Editing and Zero-Shot TTS with Cross-Attentive Mamba](http://arxiv.org/abs/2510.04738v1)** |  | 2025-10-06 |  |
| **[UniVoice: Unifying Autoregressive ASR and Flow-Matching based TTS with Large Language Models](http://arxiv.org/abs/2510.04593v1)** |  | 2025-10-06 |  |
| **[VoxCPM: Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life Voice Cloning](http://arxiv.org/abs/2509.24650v1)** |  | 2025-09-29 | Technical Report |
| **[SPADE: Structured Pruning and Adaptive Distillation for Efficient LLM-TTS](http://arxiv.org/abs/2509.20802v2)** |  | 2025-09-26 | <details><summary>Submi...</summary><p>Submitted to ICASSP 2026</p></details> |
| **[Align2Speak: Improving TTS for Low Resource Languages via ASR-Guided Online Preference Optimization](http://arxiv.org/abs/2509.21718v1)** |  | 2025-09-26 | <details><summary>Submi...</summary><p>Submitted to ICASSP 2026</p></details> |
| **[Facilitating Personalized TTS for Dysarthric Speakers Using Knowledge Anchoring and Curriculum Learning](http://arxiv.org/abs/2508.10412v2)** |  | 2025-09-25 | Interspeech 2025 |
| **[DiaMoE-TTS: A Unified IPA-Based Dialect TTS Framework with Mixture-of-Experts and Parameter-Efficient Zero-Shot Adaptation](http://arxiv.org/abs/2509.22727v1)** |  | 2025-09-25 | 5 pages, 2 figures |
| **[Eliminating stability hallucinations in llm-based tts models via attention guidance](http://arxiv.org/abs/2509.19852v1)** |  | 2025-09-24 | <details><summary>5 pag...</summary><p>5 pages, submitted to ICASSP2026</p></details> |

## Audio Caption
| **Title** | **Link** | **Date** | **Comment** |
| --- | --- | --- | --- |
| **[SeaLLMs-Audio: Large Audio-Language Models for Southeast Asia](http://arxiv.org/abs/2511.01670v1)** |  | 2025-11-03 | 10 pages |
| **[Do Joint Language-Audio Embeddings Encode Perceptual Timbre Semantics?](http://arxiv.org/abs/2510.14249v1)** |  | 2025-10-16 |  |
| **[Omni-Captioner: Data Pipeline, Models, and Benchmark for Omni Detailed Perception](http://arxiv.org/abs/2510.12720v1)** |  | 2025-10-14 | <details><summary>https...</summary><p>https://github.com/ddlBoJack/Omni-Captioner</p></details> |
| **[Adaptive vector steering: A training-free, layer-wise intervention for hallucination mitigation in large audio and multimodal models](http://arxiv.org/abs/2510.12851v1)** |  | 2025-10-14 | <details><summary>Note:...</summary><p>Note: This preprint is a version of the paper submitted to ICASSP
  2026. The author list here includes contributors who provided additional
  supervision and guidance. The official ICASSP submission may differ slightly
  in author composition</p></details> |
| **[Diffusion-Link: Diffusion Probabilistic Model for Bridging the Audio-Text Modality Gap](http://arxiv.org/abs/2510.11330v1)** |  | 2025-10-13 | <details><summary>5 pag...</summary><p>5 pages. Submitted to IEEE ICASSP 2026</p></details> |
| **[AURA Score: A Metric For Holistic Audio Question Answering Evaluation](http://arxiv.org/abs/2510.04934v1)** |  | 2025-10-06 |  |
| **[Taming Text-to-Sounding Video Generation via Advanced Modality Condition and Interaction](http://arxiv.org/abs/2510.03117v1)** |  | 2025-10-03 |  |
| **[When Audio Generators Become Good Listeners: Generative Features for Understanding Tasks](http://arxiv.org/abs/2509.24635v1)** |  | 2025-09-29 |  |
| **[CapSpeech: Enabling Downstream Applications in Style-Captioned Text-to-Speech](http://arxiv.org/abs/2506.02863v2)** |  | 2025-09-26 |  |
| **[From Contrast to Commonality: Audio Commonality Captioning for Enhanced Audio-Text Cross-modal Understanding in Multimodal LLMs](http://arxiv.org/abs/2508.01659v2)** |  | 2025-09-22 |  |
| **[Qwen3-Omni Technical Report](http://arxiv.org/abs/2509.17765v1)** |  | 2025-09-22 | <details><summary>https...</summary><p>https://github.com/QwenLM/Qwen3-Omni</p></details> |
| **[Enhancing Speech Large Language Models with Prompt-Aware Mixture of Audio Encoders](http://arxiv.org/abs/2502.15178v3)** |  | 2025-09-19 | <details><summary>16 pa...</summary><p>16 pages,5 figures, 13 tables, to be published in EMNLP 2025 main
  conference</p></details> |
| **[Mamba-2 audio captioning: design space exploration and analysis](http://arxiv.org/abs/2509.15680v1)** |  | 2025-09-19 | <details><summary>Submi...</summary><p>Submitted to the 2026 IEEE International Conference on Acoustics,
  Speech, and Signal Processing (ICASSP 2026). Under review</p></details> |
| **[Aligning Audio Captions with Human Preferences](http://arxiv.org/abs/2509.14659v1)** |  | 2025-09-18 | <details><summary>Submi...</summary><p>Submitted to ICASSP 2026</p></details> |
| **[MAGIC-Enhanced Keyword Prompting for Zero-Shot Audio Captioning with CLIP Models](http://arxiv.org/abs/2509.12591v1)** |  | 2025-09-16 | <details><summary>Accep...</summary><p>Accepted in The 26th International Conference on Web Information
  Systems Engineering (WISE), scheduled for 15-17 December 2025 in Marrakech,
  Morocco</p></details> |

## Speech language model
| **Title** | **Link** | **Date** | **Comment** |
| --- | --- | --- | --- |
| **[VoiceAgentBench: Are Voice Assistants ready for agentic tasks?](http://arxiv.org/abs/2510.07978v2)** |  | 2025-11-05 |  |
| **[FastLongSpeech: Enhancing Large Speech-Language Models for Efficient Long-Speech Processing](http://arxiv.org/abs/2507.14815v2)** |  | 2025-10-31 | <details><summary>NeurI...</summary><p>NeurIPS 2025. The code is at
  https://github.com/ictnlp/FastLongSpeech. This model is at
  https://huggingface.co/ICTNLP/FastLongSpeech. The dataset is at
  https://huggingface.co/datasets/ICTNLP/LongSpeech-Eval</p></details> |
| **[OpenS2S: Advancing Fully Open-Source End-to-End Empathetic Large Speech Language Model](http://arxiv.org/abs/2507.05177v3)** |  | 2025-10-27 | <details><summary>Techn...</summary><p>Technical Report, Update on OpenS2S_v1.5</p></details> |
| **[EchoMind: An Interrelated Multi-level Benchmark for Evaluating Empathetic Speech Language Models](http://arxiv.org/abs/2510.22758v1)** |  | 2025-10-26 | <details><summary>Speec...</summary><p>Speech Language Models, Spoken Language Understanding, Vocal Cue
  Perception, Empathetic Dialogue, Benchmark Evaluation</p></details> |
| **[Brain-tuning Improves Generalizability and Efficiency of Brain Alignment in Speech Models](http://arxiv.org/abs/2510.21520v1)** |  | 2025-10-24 | <details><summary>Publi...</summary><p>Published at the 39th Conference on Neural Information Processing
  Systems (NeurIPS 2025)</p></details> |
| **[Efficient Speech Language Modeling via Energy Distance in Continuous Latent Space](http://arxiv.org/abs/2505.13181v2)** |  | 2025-10-24 | <details><summary>NeurI...</summary><p>NeurIPS 2025; Demos and code are available at
  https://github.com/ictnlp/SLED-TTS</p></details> |
| **[Are These Even Words? Quantifying the Gibberishness of Generative Speech Models](http://arxiv.org/abs/2510.21317v1)** |  | 2025-10-24 |  |
| **[SpecTokenizer: A Lightweight Streaming Codec in the Compressed Spectrum Domain](http://arxiv.org/abs/2510.21209v1)** |  | 2025-10-24 | <details><summary>Accep...</summary><p>Accepted by Interspeech 2025; 5 pages, 1 figure, 5 tables</p></details> |
| **[Data-Centric Lessons To Improve Speech-Language Pretraining](http://arxiv.org/abs/2510.20860v1)** |  | 2025-10-22 | Tech Report |
| **[Efficient Interleaved Speech Modeling through Knowledge Distillation](http://arxiv.org/abs/2506.23670v2)** |  | 2025-10-21 |  |
| **[VITA-Audio: Fast Interleaved Cross-Modal Token Generation for Efficient Large Speech-Language Model](http://arxiv.org/abs/2505.03739v2)** |  | 2025-10-21 | <details><summary>Train...</summary><p>Training and Inference Codes: https://github.com/VITA-MLLM/VITA-Audio</p></details> |
| **[Late Fusion and Multi-Level Fission Amplify Cross-Modal Transfer in Text-Speech LMs](http://arxiv.org/abs/2503.06211v2)** |  | 2025-10-20 |  |
| **[SAC: Neural Speech Codec with Semantic-Acoustic Dual-Stream Quantization](http://arxiv.org/abs/2510.16841v1)** |  | 2025-10-19 |  |
| **[SPIRIT: Patching Speech Language Models against Jailbreak Attacks](http://arxiv.org/abs/2505.13541v2)** |  | 2025-10-16 |  |
| **[Universal Speech Token Learning via Low-Bitrate Neural Codec and Pretrained Representations](http://arxiv.org/abs/2503.12115v2)** |  | 2025-10-15 | <details><summary>Accep...</summary><p>Accepted by IEEE Journal of Selected Topics in Signal
  Processing(JSTSP)</p></details> |
